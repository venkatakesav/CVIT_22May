{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Writer Identification System Workbook\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workbook, you will develop a simple Writer Identification System using classical machine learning and image processing techniques. The system identifies the writer of a given handwritten document by analyzing the text's handwriting style.\n",
    "\n",
    "### Project Pipeline Overview\n",
    "\n",
    "1. **Preprocessing Module:** Crop the handwritten region from the image and split it into separate lines.\n",
    "2. **Feature Extraction Module:** Use Local Binary Patterns (LBP) to extract textural features from each line.\n",
    "3. **Model Training Module:** Train a k-Nearest Neighbors (KNN) classifier using the extracted features.\n",
    "4. **Performance Analysis Module:** Analyze the system's performance by comparing predicted results with actual results and calculating the processing time.\n",
    "5. **Test Generation:** Use test cases generated from the IAM dataset for evaluation.\n",
    "\n",
    "## 1. Preprocessing Module\n",
    "\n",
    "In the preprocessing stage, we focus on isolating the handwritten part of the image and then splitting this part into individual lines of text.\n",
    "\n",
    "### First Step: Crop the Handwritten Region\n",
    "\n",
    "The handwritten part is between the second and third black lines in the image. Hereâ€™s how you can detect and crop this region:\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Convert the image to a binary image using Otsu's thresholding.\n",
    "2. Find all contours in the image.\n",
    "3. Identify contours that likely represent lines based on their geometry.\n",
    "4. Sort these lines and use the second and third lines to determine the crop region.\n",
    "5. Crop and optionally erode the image to reduce noise.\n",
    "\n",
    "Below is the function to crop the handwritten region. Some parts are missing, which you need to fill in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import os\n",
    "import time\n",
    "import statistics\n",
    "\n",
    "def crop_handwritten_region(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, bin_img = cv2.threshold(imgray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(bin_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    y_array = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        if w > 1000 and h < 500:\n",
    "            y_array.append(y)\n",
    "    \n",
    "    y_array = sorted(y_array)\n",
    "    cropped_image_bin = bin_img[y_array[1]+4:y_array[2], :]\n",
    "    \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    cropped_image_bin = cv2.erode(cropped_image_bin, kernel, iterations=2)\n",
    "    \n",
    "    return cropped_image_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Step: Split Cropped Image to Separated Written Lines\n",
    "\n",
    "After cropping the handwritten region, we split this region into individual lines of text.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Calculate the sum of black pixels for each row in the binary image.\n",
    "2. Identify rows that mark the beginning and end of each line of text.\n",
    "3. Use these row indices to split the image into lines.\n",
    "\n",
    "Here is the function to split the image into lines. Fill in the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_lines(cropped_img):\n",
    "    sum_black_in_row = np.sum(cropped_img < 255, axis=1)\n",
    "    lines = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(sum_black_in_row):\n",
    "        if sum_black_in_row[i] > 15:\n",
    "            up = max(0, i - 6)\n",
    "            while i < len(sum_black_in_row) and sum_black_in_row[i] > 15:\n",
    "                i += 1\n",
    "            down = min(len(sum_black_in_row) - 1, i + 6)\n",
    "            \n",
    "            if down - up > 20:\n",
    "                lines.append(cropped_img[up:down, :])\n",
    "        i += 1\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Module\n",
    "\n",
    "Here, you will use the Local Binary Pattern (LBP) method to extract features from the handwritten lines.\n",
    "\n",
    "### Local Binary Pattern (LBP)\n",
    "\n",
    "LBP is a simple yet very efficient texture operator that labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. For each pixel, compare its value with its 8 neighbors. Follow the pixels along a circle, so the first pixel compared is the top-left and the last is the middle-left.\n",
    "2. Threshold the neighborhood with the center value and consider the result as a binary number.\n",
    "3. Convert this binary number to a decimal number and use it as a new value for the center pixel.\n",
    "\n",
    "Below is the function to calculate LBP for a single pixel. You need to complete the function by calculating the `lbp_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_calculate_pixels(img, x, y, radius=3, neighbors=8):\n",
    "    threshold = img[x, y]\n",
    "    binary_string = []\n",
    "    \n",
    "    for i in range(neighbors):\n",
    "        dx = round(radius * np.cos(2 * np.pi * i / neighbors))\n",
    "        dy = round(radius * np.sin(2 * np.pi * i / neighbors))\n",
    "        neighbor_value = img[x + dx, y + dy]\n",
    "        binary_string.append(int(neighbor_value >= threshold))\n",
    "    \n",
    "    lbp_val = sum(val * (2 ** idx) for idx, val in enumerate(binary_string))\n",
    "    return lbp_val\n",
    "\n",
    "def lbp_get_result(img):\n",
    "    height, width = img.shape\n",
    "    result_img = np.zeros((height, width), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(3, height - 3):\n",
    "        for j in range(3, width - 3):\n",
    "            result_img[i, j] = lbp_calculate_pixels(img, i, j)\n",
    "    \n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Vector from LBP\n",
    "\n",
    "After computing the LBP for each pixel, the next step is to calculate the histogram of these values. This histogram serves as a feature vector for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_hist(lbp_img):\n",
    "    histogram, _ = np.histogram(lbp_img.flatten(), bins=np.arange(257))\n",
    "    return histogram\n",
    "\n",
    "def lbp_normalize(histogram):\n",
    "    return histogram / np.mean(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training Module\n",
    "\n",
    "Using the features extracted from the LBP, you can now train a KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn(features, labels):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(features, labels)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Performance Analysis Module\n",
    "\n",
    "In this module, you evaluate the performance of your model on unseen data.\n",
    "\n",
    "```python\n",
    "def predict_and_evaluate(test_img_path, classifier):\n",
    "    _, _, test_lines = crop_handwritten_region(test_img_path)\n",
    "    test_features = [lbp_normalize(lbp_hist(lbp_get_result(line))) for line in split_lines(test_lines)]\n",
    "    \n",
    "    predictions = classifier.predict(test_features)\n",
    "    return np.bincount(predictions).argmax()\n",
    "```\n",
    "\n",
    "## 5. Test Generation\n",
    "\n",
    "Utilize the IAM dataset for generating test cases.\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. Preprocess your images using `crop_handwritten_region` and `split_lines`.\n",
    "2. Extract features using `lbp_get_result`, `lbp_hist`, and `lbp_normalize`.\n",
    "3. Train your model using `train_knn`.\n",
    "4. Predict and evaluate with `predict_and_evaluate`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [OpenCV Documentation](https://docs.opencv.org/master/)\n",
    "- [Scikit-learn KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [Numpy Documentation](https://numpy.org/doc/stable/)\n",
    "- [Matplotlib Examples](https://matplotlib.org/stable/gallery/index.html)\n",
    "- [Understanding Image Thresholding](https://learnopencv.com/otsu-thresholding-with-opencv/)\n",
    "\n",
    "Feel free to search these terms in Google for more information:\n",
    "\n",
    "- \"Local Binary Patterns\"\n",
    "- \"Image Contouring in OpenCV\"\n",
    "- \"Histograms in Image Processing\"\n",
    "- \"K-Nearest Neighbors Algorithm\"\n",
    "- \"Image Preprocessing Techniques\"\n",
    "\n",
    "---\n",
    "\n",
    "This workbook provides a structured approach to building a Writer Identification System using classical machine learning techniques in Python. Ensure to fill in the missing parts and understand each step to get the most out of this exercise!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
